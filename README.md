# A2A-MCP: Agent-to-Agent Model Control Protocol

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](License.md)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![uv](https://img.shields.io/badge/managed%20with-uv-purple.svg)](https://github.com/astral-sh/uv)

A sophisticated multi-agent system that combines the Model Context Protocol (MCP) with Agent-to-Agent (A2A) communication for intelligent text processing, web interaction, and automated workflows.

## ğŸŒŸ Features

### ğŸ¤– Intelligent Multi-Agent System
- **Smart Agent Coordination**: Automatic detection of user intent and routing to appropriate agents
- **A2A Communication**: Direct agent-to-agent communication for complex workflows
- **MCP Integration**: Standards-compliant Model Context Protocol implementation

### ğŸ”§ Core Services (MCP Tools)
- **Web Search & Weather**: DuckDuckGo integration with weather-specific queries
- **Website Content Extraction**: Headless browser-based text extraction
- **Time & Date Services**: NTP-synchronized accurate time information
- **File Processing**: Multi-format document conversion to PDF
- **Data Anonymization**: Intelligent PII detection and removal

### ğŸ¯ Specialized Agents (A2A)
- **Text Optimizer**: Professional email generation and tone adjustment
- **Grammar Corrector (Lektor)**: German/English grammar and spelling correction
- **Sentiment Analysis**: Emotion detection and sentiment scoring
- **Query Refactoring**: LLM-optimized query reformulation
- **User Interface Agent**: Intelligent request interpretation and routing

### ğŸŒ User Interfaces
- **Gradio Web Interface**: User-friendly browser-based interaction
- **RESTful API**: Programmatic access to all services
- **CLI Integration**: Command-line tool compatibility

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    A2A-MCP System                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Gradio Interface (Port 7860)                              â”‚
â”‚  â”œâ”€â”€ File Upload & Processing                              â”‚
â”‚  â”œâ”€â”€ Natural Language Input                                â”‚
â”‚  â””â”€â”€ Tonality Selection                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User Interface Agent (Intelligent Router)                 â”‚
â”‚  â”œâ”€â”€ Intent Detection                                      â”‚
â”‚  â”œâ”€â”€ Agent Selection                                       â”‚
â”‚  â””â”€â”€ Response Coordination                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MCP Server (Port 8000)                     A2A Registry   â”‚
â”‚  â”œâ”€â”€ Web Search & Weather                   â”œâ”€â”€ Optimizer  â”‚
â”‚  â”œâ”€â”€ Website Extraction                     â”œâ”€â”€ Lektor     â”‚
â”‚  â”œâ”€â”€ Time/Date Services                     â”œâ”€â”€ Sentiment  â”‚
â”‚  â”œâ”€â”€ File Conversion                        â”œâ”€â”€ Query Ref  â”‚
â”‚  â””â”€â”€ Anonymization                          â””â”€â”€ UI Agent   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Backend Services                                          â”‚
â”‚  â”œâ”€â”€ Selenium WebDriver                                    â”‚
â”‚  â”œâ”€â”€ DuckDuckGo Search                                     â”‚
â”‚  â”œâ”€â”€ NTP Time Sync                                         â”‚
â”‚  â”œâ”€â”€ PDF Conversion                                        â”‚
â”‚  â””â”€â”€ LLM Integration (Ollama)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- [Ollama](https://ollama.ai/) with `qwen2.5:latest` model
- Modern web browser (for Gradio interface)

### Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd a2a_mcp
   ```

2. **Install dependencies**:
   ```bash
   # Using uv (recommended)
   uv sync
   
   # Or using pip
   pip install -r requirements.txt
   ```

3. **Configure environment**:
   ```bash
   cp .env.example .env
   # Edit .env with your settings
   ```

4. **Start Ollama** (if not running):
   ```bash
   ollama serve
   ollama pull qwen2.5:latest
   ```

### Quick Launch

Start all services with the integrated launcher:

```bash
python launcher.py
```

This will automatically start:
- **MCP Server** on `http://localhost:8000`
- **Gradio Interface** on `http://localhost:7860`
- **A2A Agent Registry** (embedded)

## ğŸ¯ Usage Examples

### Web Interface

1. **Open your browser** to `http://localhost:7860`
2. **Try these example requests**:

```
"Wie wird das Wetter morgen in Berlin?"
â†’ Automatic web search with weather optimization

"Korrigiere diesen Text: Das ist ein sehr schlechte Satz mit viele Fehler."
â†’ Grammar correction via Lektor agent

"Optimiere diesen Text fÃ¼r eine professionelle E-Mail: Das Produkt ist Schrott!"
â†’ Professional email generation via Optimizer agent

"Analysiere das Sentiment: Ich bin so glÃ¼cklich Ã¼ber dieses groÃŸartige Produkt!"
â†’ Sentiment analysis with emotion detection

"Wie spÃ¤t ist es jetzt?"
â†’ NTP-synchronized time retrieval
```

### API Usage

```python
import httpx

# Direct MCP tool call
async with httpx.AsyncClient() as client:
    response = await client.post(
        "http://localhost:8000/mcp/call-tool",
        json={
            "name": "duckduckgo_search",
            "arguments": {"query": "weather Berlin", "max_results": 5}
        }
    )
    print(response.json())
```

### Agent Integration

```python
from agent_server.user_interface import process_input

# Intelligent request processing
result = await process_input("Mache diesen Text freundlicher: Ihre Anfrage wurde abgelehnt.")
print(result.final_result)
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# LLM Configuration
BASE_URL=http://localhost:11434/v1
API_KEY=ollama
USER_INTERFACE_MODEL=qwen2.5:latest
OPTIMIZER_MODEL=qwen2.5:latest
LEKTOR_MODEL=qwen2.5:latest
SENTIMENT_MODEL=qwen2.5:latest
QUERY_REF_MODEL=qwen2.5:latest

# Server Configuration
SERVER_HOST=localhost
SERVER_PORT=8000
SERVER_SCHEME=http
GRADIO_HOST=127.0.0.1
GRADIO_PORT=7860

# Debug Options
DEBUG_AGENT_RESPONSES=false
DEBUG_A2A_CALLS=false

# Service Configuration
ANONYMIZER_USE_LLM=false
ANONYMIZER_LLM_ENDPOINT=
ANONYMIZER_LLM_API_KEY=
ANONYMIZER_LLM_MODEL=
```

### Model Requirements

Ensure these models are available in Ollama:
```bash
ollama pull qwen2.5:latest  # Primary model for all agents
# Or configure different models per agent in .env
```

## ğŸ“š Available Tools & Agents

### MCP Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `get_current_time` | NTP-synchronized UTC time | None |
| `duckduckgo_search` | Web search with weather optimization | `query`, `max_results` |
| `extract_website_text` | Extract main content from URLs | `url` |
| `anonymize_text` | Remove PII from text | `text` |
| `convert_to_pdf` | Convert files to PDF format | `input_filepath`, `output_directory` |

### A2A Agents

| Agent | Purpose | Input | Output |
|-------|---------|-------|--------|
| **Optimizer** | Professional text optimization | Raw text + tonality | Polished professional text |
| **Lektor** | Grammar & spelling correction | Text with errors | Corrected text |
| **Sentiment** | Emotion & sentiment analysis | Any text | Sentiment score + emotions |
| **Query Ref** | LLM query optimization | User query | Optimized query |
| **User Interface** | Intelligent request routing | Natural language | Coordinated response |

### Supported File Types

#### Text Processing
- `.txt`, `.md`, `.py`, `.csv`, `.log`, `.json`, `.xml`, `.html`

#### PDF Conversion
- **Text files**: All above formats
- **Images**: `.jpg`, `.png`, `.gif`, `.bmp`, `.tiff`, `.webp`
- **Office docs**: `.docx`, `.xlsx`, `.pptx` (requires LibreOffice)

## ğŸ”„ Workflows

### Intelligent Text Processing
```
User Input â†’ Intent Detection â†’ Agent Selection â†’ Processing â†’ Response
     â†“              â†“              â†“              â†“          â†“
"Fix grammar" â†’ Text Processing â†’ Lektor Agent â†’ Correction â†’ Clean Text
```

### Professional Email Generation
```
Complaint Text â†’ Optimizer Agent â†’ Professional Email â†’ Lektor Check â†’ Final Email
```

### Multi-Step Analysis
```
Raw Text â†’ Query Refactor â†’ Optimization â†’ Grammar Check â†’ Sentiment Analysis
```

## ğŸ› ï¸ Development

### Project Structure

```
a2a_mcp/
â”œâ”€â”€ agent_server/           # A2A agents
â”‚   â”œâ”€â”€ user_interface.py   # Main coordination agent
â”‚   â”œâ”€â”€ optimizer.py        # Text optimization
â”‚   â”œâ”€â”€ lektor.py          # Grammar correction
â”‚   â”œâ”€â”€ sentiment.py       # Sentiment analysis
â”‚   â””â”€â”€ query_ref.py       # Query refactoring
â”œâ”€â”€ mcp_services/          # MCP service implementations
â”‚   â”œâ”€â”€ mcp_search/        # DuckDuckGo integration
â”‚   â”œâ”€â”€ mcp_website/       # Web scraping
â”‚   â”œâ”€â”€ mcp_time/         # NTP time services
â”‚   â”œâ”€â”€ mcp_anonymizer/   # Data anonymization
â”‚   â””â”€â”€ mcp_fileconverter/ # PDF conversion
â”œâ”€â”€ mcp_main.py           # MCP server
â”œâ”€â”€ launcher.py           # Service orchestrator
â”œâ”€â”€ gradio_interface.py   # Web UI
â”œâ”€â”€ a2a_server.py        # A2A registry
â””â”€â”€ uploaded_files/      # File upload storage
```

### Adding New Agents

1. **Create agent file** in `agent_server/`:
```python
from pydantic_ai import Agent
from pydantic import BaseModel

class MyAgentResponse(BaseModel):
    result: str

async def my_agent_a2a_function(messages: list) -> MyAgentResponse:
    # Implementation
    pass
```

2. **Register in A2A server**:
```python
# In a2a_server.py
registry.register_a2a_agent("my_agent", my_agent_a2a_function)
```

3. **Add to user interface** agent routing logic

### Adding MCP Tools

1. **Implement service** in `mcp_services/`
2. **Add endpoint** in `mcp_main.py`
3. **Register tool** in MCP configuration

## ğŸ§ª Testing

### Manual Testing
```bash
# Test individual agents
python agent_server/sentiment.py
python agent_server/optimizer.py

# Test MCP server
curl http://localhost:8000/health

# Test full workflow
python a2a_server.py
```

### Example Test Cases
```python
# Sentiment analysis
await sentiment_agent("I love this amazing product!")

# Text optimization
await optimizer_agent("Das Produkt ist Schrott!", tonality="professionell")

# Grammar correction
await lektor_agent("Das ist ein sehr schlechte Satz.")
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the AGPL v3 License - see the [License.md](License.md) file for details.

## ğŸ™ Acknowledgments

- [Pydantic AI](https://github.com/pydantic/pydantic-ai) for the agent framework
- [Model Context Protocol](https://modelcontextprotocol.io/) for the standards
- [Gradio](https://gradio.app/) for the web interface
- [Ollama](https://ollama.ai/) for local LLM support

---

**Built with â¤ï¸ for intelligent multi-agent workflows**
